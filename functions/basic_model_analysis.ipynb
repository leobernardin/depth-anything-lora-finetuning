{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e169a1e",
   "metadata": {},
   "source": [
    "## Model overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccab0491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "pretrained.cls_token torch.Size([1, 1, 1024])\n",
      "pretrained.pos_embed torch.Size([1, 1370, 1024])\n",
      "pretrained.mask_token torch.Size([1, 1024])\n",
      "pretrained.patch_embed.proj.weight torch.Size([1024, 3, 14, 14])\n",
      "pretrained.patch_embed.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.0.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.0.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.0.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.0.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.0.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.0.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.0.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.0.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.0.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.0.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.0.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.0.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.0.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.0.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.1.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.1.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.1.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.1.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.1.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.1.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.1.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.1.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.1.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.1.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.1.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.1.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.1.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.1.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.2.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.2.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.2.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.2.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.2.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.2.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.2.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.2.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.2.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.2.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.2.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.2.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.2.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.2.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.3.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.3.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.3.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.3.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.3.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.3.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.3.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.3.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.3.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.3.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.3.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.3.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.3.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.3.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.4.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.4.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.4.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.4.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.4.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.4.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.4.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.4.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.4.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.4.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.4.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.4.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.4.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.4.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.5.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.5.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.5.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.5.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.5.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.5.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.5.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.5.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.5.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.5.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.5.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.5.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.5.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.5.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.6.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.6.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.6.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.6.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.6.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.6.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.6.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.6.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.6.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.6.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.6.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.6.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.6.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.6.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.7.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.7.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.7.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.7.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.7.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.7.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.7.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.7.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.7.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.7.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.7.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.7.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.7.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.7.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.8.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.8.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.8.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.8.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.8.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.8.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.8.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.8.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.8.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.8.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.8.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.8.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.8.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.8.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.9.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.9.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.9.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.9.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.9.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.9.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.9.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.9.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.9.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.9.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.9.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.9.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.9.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.9.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.10.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.10.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.10.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.10.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.10.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.10.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.10.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.10.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.10.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.10.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.10.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.10.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.10.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.10.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.11.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.11.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.11.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.11.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.11.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.11.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.11.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.11.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.11.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.11.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.11.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.11.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.11.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.11.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.12.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.12.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.12.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.12.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.12.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.12.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.12.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.12.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.12.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.12.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.12.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.12.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.12.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.12.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.13.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.13.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.13.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.13.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.13.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.13.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.13.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.13.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.13.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.13.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.13.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.13.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.13.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.13.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.14.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.14.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.14.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.14.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.14.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.14.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.14.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.14.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.14.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.14.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.14.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.14.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.14.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.14.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.15.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.15.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.15.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.15.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.15.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.15.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.15.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.15.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.15.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.15.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.15.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.15.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.15.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.15.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.16.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.16.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.16.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.16.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.16.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.16.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.16.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.16.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.16.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.16.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.16.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.16.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.16.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.16.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.17.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.17.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.17.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.17.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.17.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.17.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.17.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.17.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.17.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.17.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.17.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.17.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.17.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.17.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.18.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.18.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.18.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.18.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.18.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.18.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.18.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.18.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.18.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.18.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.18.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.18.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.18.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.18.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.19.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.19.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.19.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.19.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.19.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.19.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.19.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.19.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.19.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.19.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.19.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.19.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.19.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.19.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.20.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.20.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.20.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.20.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.20.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.20.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.20.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.20.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.20.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.20.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.20.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.20.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.20.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.20.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.21.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.21.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.21.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.21.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.21.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.21.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.21.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.21.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.21.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.21.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.21.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.21.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.21.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.21.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.22.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.22.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.22.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.22.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.22.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.22.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.22.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.22.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.22.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.22.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.22.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.22.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.22.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.22.ls2.gamma torch.Size([1024])\n",
      "pretrained.blocks.23.norm1.weight torch.Size([1024])\n",
      "pretrained.blocks.23.norm1.bias torch.Size([1024])\n",
      "pretrained.blocks.23.attn.qkv.weight torch.Size([3072, 1024])\n",
      "pretrained.blocks.23.attn.qkv.bias torch.Size([3072])\n",
      "pretrained.blocks.23.attn.proj.weight torch.Size([1024, 1024])\n",
      "pretrained.blocks.23.attn.proj.bias torch.Size([1024])\n",
      "pretrained.blocks.23.ls1.gamma torch.Size([1024])\n",
      "pretrained.blocks.23.norm2.weight torch.Size([1024])\n",
      "pretrained.blocks.23.norm2.bias torch.Size([1024])\n",
      "pretrained.blocks.23.mlp.fc1.weight torch.Size([4096, 1024])\n",
      "pretrained.blocks.23.mlp.fc1.bias torch.Size([4096])\n",
      "pretrained.blocks.23.mlp.fc2.weight torch.Size([1024, 4096])\n",
      "pretrained.blocks.23.mlp.fc2.bias torch.Size([1024])\n",
      "pretrained.blocks.23.ls2.gamma torch.Size([1024])\n",
      "pretrained.norm.weight torch.Size([1024])\n",
      "pretrained.norm.bias torch.Size([1024])\n",
      "depth_head.projects.0.weight torch.Size([256, 1024, 1, 1])\n",
      "depth_head.projects.0.bias torch.Size([256])\n",
      "depth_head.projects.1.weight torch.Size([512, 1024, 1, 1])\n",
      "depth_head.projects.1.bias torch.Size([512])\n",
      "depth_head.projects.2.weight torch.Size([1024, 1024, 1, 1])\n",
      "depth_head.projects.2.bias torch.Size([1024])\n",
      "depth_head.projects.3.weight torch.Size([1024, 1024, 1, 1])\n",
      "depth_head.projects.3.bias torch.Size([1024])\n",
      "depth_head.resize_layers.0.weight torch.Size([256, 256, 4, 4])\n",
      "depth_head.resize_layers.0.bias torch.Size([256])\n",
      "depth_head.resize_layers.1.weight torch.Size([512, 512, 2, 2])\n",
      "depth_head.resize_layers.1.bias torch.Size([512])\n",
      "depth_head.resize_layers.3.weight torch.Size([1024, 1024, 3, 3])\n",
      "depth_head.resize_layers.3.bias torch.Size([1024])\n",
      "depth_head.scratch.layer1_rn.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.layer2_rn.weight torch.Size([256, 512, 3, 3])\n",
      "depth_head.scratch.layer3_rn.weight torch.Size([256, 1024, 3, 3])\n",
      "depth_head.scratch.layer4_rn.weight torch.Size([256, 1024, 3, 3])\n",
      "depth_head.scratch.refinenet1.out_conv.weight torch.Size([256, 256, 1, 1])\n",
      "depth_head.scratch.refinenet1.out_conv.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet1.resConfUnit1.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet1.resConfUnit1.conv1.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet1.resConfUnit1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet1.resConfUnit1.conv2.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet1.resConfUnit2.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet1.resConfUnit2.conv1.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet1.resConfUnit2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet1.resConfUnit2.conv2.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet2.out_conv.weight torch.Size([256, 256, 1, 1])\n",
      "depth_head.scratch.refinenet2.out_conv.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet2.resConfUnit1.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet2.resConfUnit1.conv1.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet2.resConfUnit1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet2.resConfUnit1.conv2.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet2.resConfUnit2.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet2.resConfUnit2.conv1.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet2.resConfUnit2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet2.resConfUnit2.conv2.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet3.out_conv.weight torch.Size([256, 256, 1, 1])\n",
      "depth_head.scratch.refinenet3.out_conv.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet3.resConfUnit1.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet3.resConfUnit1.conv1.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet3.resConfUnit1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet3.resConfUnit1.conv2.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet3.resConfUnit2.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet3.resConfUnit2.conv1.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet3.resConfUnit2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet3.resConfUnit2.conv2.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet4.out_conv.weight torch.Size([256, 256, 1, 1])\n",
      "depth_head.scratch.refinenet4.out_conv.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet4.resConfUnit1.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet4.resConfUnit1.conv1.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet4.resConfUnit1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet4.resConfUnit1.conv2.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet4.resConfUnit2.conv1.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet4.resConfUnit2.conv1.bias torch.Size([256])\n",
      "depth_head.scratch.refinenet4.resConfUnit2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "depth_head.scratch.refinenet4.resConfUnit2.conv2.bias torch.Size([256])\n",
      "depth_head.scratch.output_conv1.weight torch.Size([128, 256, 3, 3])\n",
      "depth_head.scratch.output_conv1.bias torch.Size([128])\n",
      "depth_head.scratch.output_conv2.0.weight torch.Size([32, 128, 3, 3])\n",
      "depth_head.scratch.output_conv2.0.bias torch.Size([32])\n",
      "depth_head.scratch.output_conv2.2.weight torch.Size([1, 32, 1, 1])\n",
      "depth_head.scratch.output_conv2.2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "pth_path = r\"C:\\Github\\Projet_Transformers\\models\\depth_anything_v2_vitl.pth\" #path to change\n",
    "\n",
    "state_dict = torch.load(pth_path, map_location=\"cpu\")\n",
    "\n",
    "print(type(state_dict))\n",
    "\n",
    "for key, value in state_dict.items():\n",
    "    print(key, value.shape if hasattr(value, \"shape\") else type(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ebad78",
   "metadata": {},
   "source": [
    "## Number of model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b003f180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters : 335,315,649\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load(pth_path, map_location=\"cpu\")\n",
    "\n",
    "total_params = sum(v.numel() for v in state_dict.values())\n",
    "print(f\"Total number of parameters : {total_params:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
